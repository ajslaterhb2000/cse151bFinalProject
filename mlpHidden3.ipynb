{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2791.70427041 1064.76260345]]]\n",
      "4100.326502228328\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "        \n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "        \n",
    "    elif split == 'val':\n",
    "        f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "        \n",
    "        f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.8):]\n",
    "    \n",
    "    else:\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)\n",
    "\n",
    "    return inputs, outputs\n",
    "def get_cities_trajectories(split=\"train\"):\n",
    "    inputs_cities = None\n",
    "    outputs_cities = None\n",
    "    for city in cities:\n",
    "        if split==\"train\":\n",
    "            f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "            inputs = pickle.load(open(f_in, \"rb\"))\n",
    "            n = len(inputs)\n",
    "            inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "            f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "            outputs = pickle.load(open(f_out, \"rb\"))\n",
    "            outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "        elif split == 'val':\n",
    "            f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "            inputs = pickle.load(open(f_in, \"rb\"))\n",
    "            n = len(inputs)\n",
    "            inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "\n",
    "            f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "            outputs = pickle.load(open(f_out, \"rb\"))\n",
    "            outputs = np.asarray(outputs)[int(n * 0.8):] \n",
    "        else:\n",
    "            f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "            inputs = pickle.load(open(f_in, \"rb\"))\n",
    "            n = len(inputs)\n",
    "            inputs = np.asarray(inputs)\n",
    "            outputs= None\n",
    "        if inputs_cities is None:\n",
    "            inputs_cities =inputs\n",
    "        else:\n",
    "            i = (np.concatenate((inputs_cities, inputs), axis=0))\n",
    "            inputs_cities = i\n",
    "        if outputs_cities is None:\n",
    "            outputs_cities = outputs\n",
    "        else:\n",
    "            o = np.concatenate((outputs_cities, outputs), axis=0)\n",
    "            outputs_cities= o\n",
    "    return inputs_cities, outputs_cities  \n",
    "\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_cities_trajectories(split=split)\n",
    "        global_mean = np.mean(self.inputs, axis = (0,1), keepdims = True)\n",
    "        global_std = np.std(np.sqrt(self.inputs[:, :, 0]**2 + self.inputs[:, :, 0]**2))\n",
    "        print(global_mean)\n",
    "        print(global_std)\n",
    "        #if split == \"train\":\n",
    "            #self.inputs = (self.inputs - global_mean)/global_std\n",
    "            \n",
    "            #self.outputs = (self.outputs - global_mean)/global_std\n",
    "        #else:\n",
    "            #self.inputs = (self.inputs - global_mean)/global_std\n",
    "            #self.outputs = (self.outputs - global_mean)/global_std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'miami' \n",
    "split = 'train'\n",
    "train_dataset  = ArgoverseDataset(split = split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a174510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2779.01081344 1063.5660105 ]]]\n",
      "4124.162302888706\n",
      "163051\n",
      "40765\n"
     ]
    }
   ],
   "source": [
    "val_dataset = ArgoverseDataset(split = 'val')\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a44d7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40765\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(len(val_dataset))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa73bd",
   "metadata": {},
   "source": [
    "batch_sz = 16  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d1f0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 128# batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5b7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "class mlp(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(100, 110),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(110, 110),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(110, 110),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(110, 110),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(110, 120)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 100).float()\n",
    "        x = self.mlp(x)\n",
    "        x = x.reshape(-1, 60, 2)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adbc1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pred = mlp()\n",
    "pred.to(device)\n",
    "#opt = optim.LBFGS( pred.parameters(),lr=.005)\n",
    "opt = optim.Adam(pred.parameters(), lr=.00001,weight_decay=0.9)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4725237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 214373.14879608154\n",
      "epoch 1 loss: 215269.27643585205\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25504\\1575841008.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                    maximize=group['maximize'])\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        \n",
    "        inp, out = sample_batch\n",
    "        inp = inp.to(device)\n",
    "        out = out.to(device).float()\n",
    "        preds = pred(inp)\n",
    "        opt.zero_grad()\n",
    "        loss = loss_func(preds,out)\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print('epoch {} loss: {}'.format(epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da57dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 53968.561264396434\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz)\n",
    "inputs, outputs = get_cities_trajectories(split=\"val\")\n",
    "val_loss = 0\n",
    "global_mean = np.mean(inputs, axis = (0,1), keepdims = True)\n",
    "global_std = np.std(np.sqrt(inputs[:, :, 0]**2 + inputs[:, :, 0]**2))\n",
    "gm = torch.from_numpy(global_mean).to(device)\n",
    "gs = (global_std)\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, out = sample_batch\n",
    "    inp, out = inp.to(device), out.to(device)\n",
    "   # print(out.size())\n",
    "    preds = pred(inp)\n",
    "    #preds = (preds * gs ) + gm\n",
    "    loss = loss_func(preds,out)\n",
    "    val_loss += loss.item()\n",
    "print('loss: {}'.format(val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 50, 2]) torch.Size([128, 60, 2])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    print(inp.shape, out.shape)\n",
    "    break\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "      implement your Deep learning model\n",
    "      implement training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "def get_traj_pred(test_traj_in):\n",
    "    test_data = torch.tensor(test_traj_in).to(device)\n",
    "    test_preds = pred(test_data.float())\n",
    "    #est_preds.detach().numpy()\n",
    "    return test_preds.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dc483df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=110, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=110, out_features=110, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=110, out_features=110, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=110, out_features=110, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Linear(in_features=110, out_features=120, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00333419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing city austin\n",
      "(6325, 50, 2)\n",
      "(6325, 60, 2)\n",
      "(6325, 120)\n",
      "Processing city miami\n",
      "(7971, 50, 2)\n",
      "(7971, 60, 2)\n",
      "(7971, 120)\n",
      "Processing city pittsburgh\n",
      "(6361, 50, 2)\n",
      "(6361, 60, 2)\n",
      "(6361, 120)\n",
      "Processing city dearborn\n",
      "(3671, 50, 2)\n",
      "(3671, 60, 2)\n",
      "(3671, 120)\n",
      "Processing city washington-dc\n",
      "(3829, 50, 2)\n",
      "(3829, 60, 2)\n",
      "(3829, 120)\n",
      "Processing city palo-alto\n",
      "(1686, 50, 2)\n",
      "(1686, 60, 2)\n",
      "(1686, 120)\n"
     ]
    }
   ],
   "source": [
    "num_pred_steps=60\n",
    "all_preds = np.zeros(shape=(0, num_pred_steps * 2))\n",
    "city_col = np.array([])\n",
    "\n",
    "for city_name in cities:\n",
    "\n",
    "    print(\"Processing city\", city_name)\n",
    "    \n",
    "    test_traj_in, test_traj_out = get_city_trajectories(city=city_name, split=\"test\")\n",
    "    print(test_traj_in.shape)\n",
    "    \n",
    "    test_pred_arr = get_traj_pred(test_traj_in)\n",
    "    print(test_pred_arr.shape)\n",
    "    \n",
    "    test_pred_arr_reshaped = np.reshape(test_pred_arr, newshape=(test_traj_in.shape[0], num_pred_steps * 2))\n",
    "    print(test_pred_arr_reshaped.shape)\n",
    "\n",
    "    all_preds = np.r_[all_preds, test_pred_arr_reshaped]\n",
    "    city_col = np.r_[city_col, [str(i) + \"_\" + city_name for i in range(test_pred_arr.shape[0])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a2eec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sub_df = pd.DataFrame(np.c_[city_col, all_preds], columns=[np.r_[[\"ID\"], [\"v\" + str(i) for i in range(120)]]])\n",
    "sub_df.to_csv('mlpcopy1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6d26468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v110</th>\n",
       "      <th>v111</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v114</th>\n",
       "      <th>v115</th>\n",
       "      <th>v116</th>\n",
       "      <th>v117</th>\n",
       "      <th>v118</th>\n",
       "      <th>v119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29838</th>\n",
       "      <td>1681_palo-alto</td>\n",
       "      <td>-1400.001709</td>\n",
       "      <td>-490.278046</td>\n",
       "      <td>-1398.489258</td>\n",
       "      <td>-491.101532</td>\n",
       "      <td>-1397.152588</td>\n",
       "      <td>-489.412506</td>\n",
       "      <td>-1396.301880</td>\n",
       "      <td>-490.349731</td>\n",
       "      <td>-1399.720947</td>\n",
       "      <td>...</td>\n",
       "      <td>-1398.270752</td>\n",
       "      <td>-490.230621</td>\n",
       "      <td>-1398.531982</td>\n",
       "      <td>-491.306915</td>\n",
       "      <td>-1399.746948</td>\n",
       "      <td>-490.097809</td>\n",
       "      <td>-1399.775024</td>\n",
       "      <td>-490.995911</td>\n",
       "      <td>-1398.764648</td>\n",
       "      <td>-491.166260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29839</th>\n",
       "      <td>1682_palo-alto</td>\n",
       "      <td>128.807724</td>\n",
       "      <td>-5.158374</td>\n",
       "      <td>127.608452</td>\n",
       "      <td>-2.295990</td>\n",
       "      <td>128.302399</td>\n",
       "      <td>-2.850490</td>\n",
       "      <td>128.636063</td>\n",
       "      <td>-3.031444</td>\n",
       "      <td>128.958725</td>\n",
       "      <td>...</td>\n",
       "      <td>127.355484</td>\n",
       "      <td>-1.271336</td>\n",
       "      <td>127.764763</td>\n",
       "      <td>-1.466748</td>\n",
       "      <td>128.860306</td>\n",
       "      <td>-0.626090</td>\n",
       "      <td>131.073715</td>\n",
       "      <td>-2.348398</td>\n",
       "      <td>128.352905</td>\n",
       "      <td>0.057585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29840</th>\n",
       "      <td>1683_palo-alto</td>\n",
       "      <td>-1438.665161</td>\n",
       "      <td>2158.782471</td>\n",
       "      <td>-1445.811035</td>\n",
       "      <td>2161.149902</td>\n",
       "      <td>-1448.554565</td>\n",
       "      <td>2158.391113</td>\n",
       "      <td>-1436.380615</td>\n",
       "      <td>2167.306641</td>\n",
       "      <td>-1438.968384</td>\n",
       "      <td>...</td>\n",
       "      <td>-1432.543335</td>\n",
       "      <td>2170.887207</td>\n",
       "      <td>-1438.330811</td>\n",
       "      <td>2158.953125</td>\n",
       "      <td>-1444.100342</td>\n",
       "      <td>2166.932373</td>\n",
       "      <td>-1435.093750</td>\n",
       "      <td>2157.525635</td>\n",
       "      <td>-1433.885620</td>\n",
       "      <td>2166.735596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29841</th>\n",
       "      <td>1684_palo-alto</td>\n",
       "      <td>1089.548218</td>\n",
       "      <td>1407.595215</td>\n",
       "      <td>1080.628540</td>\n",
       "      <td>1409.224854</td>\n",
       "      <td>1081.272827</td>\n",
       "      <td>1405.531982</td>\n",
       "      <td>1086.013184</td>\n",
       "      <td>1409.551636</td>\n",
       "      <td>1086.501465</td>\n",
       "      <td>...</td>\n",
       "      <td>1087.648438</td>\n",
       "      <td>1411.053711</td>\n",
       "      <td>1087.493042</td>\n",
       "      <td>1415.951172</td>\n",
       "      <td>1087.525635</td>\n",
       "      <td>1408.401855</td>\n",
       "      <td>1088.188721</td>\n",
       "      <td>1407.814209</td>\n",
       "      <td>1087.617188</td>\n",
       "      <td>1406.920044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29842</th>\n",
       "      <td>1685_palo-alto</td>\n",
       "      <td>5.193674</td>\n",
       "      <td>396.748840</td>\n",
       "      <td>9.440820</td>\n",
       "      <td>398.405975</td>\n",
       "      <td>4.385119</td>\n",
       "      <td>394.863464</td>\n",
       "      <td>5.193655</td>\n",
       "      <td>396.035736</td>\n",
       "      <td>8.839888</td>\n",
       "      <td>...</td>\n",
       "      <td>5.477061</td>\n",
       "      <td>395.916534</td>\n",
       "      <td>10.489322</td>\n",
       "      <td>397.052155</td>\n",
       "      <td>6.081702</td>\n",
       "      <td>394.673859</td>\n",
       "      <td>5.172849</td>\n",
       "      <td>397.361511</td>\n",
       "      <td>5.744670</td>\n",
       "      <td>390.975800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID           v0           v1           v2           v3  \\\n",
       "29838  1681_palo-alto -1400.001709  -490.278046 -1398.489258  -491.101532   \n",
       "29839  1682_palo-alto   128.807724    -5.158374   127.608452    -2.295990   \n",
       "29840  1683_palo-alto -1438.665161  2158.782471 -1445.811035  2161.149902   \n",
       "29841  1684_palo-alto  1089.548218  1407.595215  1080.628540  1409.224854   \n",
       "29842  1685_palo-alto     5.193674   396.748840     9.440820   398.405975   \n",
       "\n",
       "                v4           v5           v6           v7           v8  ...  \\\n",
       "29838 -1397.152588  -489.412506 -1396.301880  -490.349731 -1399.720947  ...   \n",
       "29839   128.302399    -2.850490   128.636063    -3.031444   128.958725  ...   \n",
       "29840 -1448.554565  2158.391113 -1436.380615  2167.306641 -1438.968384  ...   \n",
       "29841  1081.272827  1405.531982  1086.013184  1409.551636  1086.501465  ...   \n",
       "29842     4.385119   394.863464     5.193655   396.035736     8.839888  ...   \n",
       "\n",
       "              v110         v111         v112         v113         v114  \\\n",
       "29838 -1398.270752  -490.230621 -1398.531982  -491.306915 -1399.746948   \n",
       "29839   127.355484    -1.271336   127.764763    -1.466748   128.860306   \n",
       "29840 -1432.543335  2170.887207 -1438.330811  2158.953125 -1444.100342   \n",
       "29841  1087.648438  1411.053711  1087.493042  1415.951172  1087.525635   \n",
       "29842     5.477061   395.916534    10.489322   397.052155     6.081702   \n",
       "\n",
       "              v115         v116         v117         v118         v119  \n",
       "29838  -490.097809 -1399.775024  -490.995911 -1398.764648  -491.166260  \n",
       "29839    -0.626090   131.073715    -2.348398   128.352905     0.057585  \n",
       "29840  2166.932373 -1435.093750  2157.525635 -1433.885620  2166.735596  \n",
       "29841  1408.401855  1088.188721  1407.814209  1087.617188  1406.920044  \n",
       "29842   394.673859     5.172849   397.361511     5.744670   390.975800  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('mlpcopy1.csv')\n",
    "sample_sub.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e225e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
