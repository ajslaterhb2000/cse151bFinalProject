{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2791.70427041 1064.76260345]]]\n",
      "4100.326502228328\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_cities_trajectories(split=\"train\"):\n",
    "    inputs_cities = None\n",
    "    outputs_cities = None\n",
    "    for city in cities:\n",
    "        if split==\"train\":\n",
    "            f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "            inputs = pickle.load(open(f_in, \"rb\"))\n",
    "            n = len(inputs)\n",
    "            inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "            f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "            outputs = pickle.load(open(f_out, \"rb\"))\n",
    "            outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "        elif split == 'val':\n",
    "            f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "            inputs = pickle.load(open(f_in, \"rb\"))\n",
    "            n = len(inputs)\n",
    "            inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "\n",
    "            f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "            outputs = pickle.load(open(f_out, \"rb\"))\n",
    "            outputs = np.asarray(outputs)[int(n * 0.8):] \n",
    "        else:\n",
    "            f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "            inputs = pickle.load(open(f_in, \"rb\"))\n",
    "            n = len(inputs)\n",
    "            inputs = np.asarray(inputs)\n",
    "            outputs= None\n",
    "        if inputs_cities is None:\n",
    "            inputs_cities =inputs\n",
    "        else:\n",
    "            i = (np.concatenate((inputs_cities, inputs), axis=0))\n",
    "            inputs_cities = i\n",
    "        if outputs_cities is None:\n",
    "            outputs_cities = outputs\n",
    "        else:\n",
    "            o = np.concatenate((outputs_cities, outputs), axis=0)\n",
    "            outputs_cities= o\n",
    "    return inputs_cities, outputs_cities  \n",
    "\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_cities_trajectories(split=split)\n",
    "        global_mean = np.mean(self.inputs, axis = (0,1), keepdims = True)\n",
    "        global_std = np.std(np.sqrt(self.inputs[:, :, 0]**2 + self.inputs[:, :, 0]**2))\n",
    "        print(global_mean)\n",
    "        print(global_std)\n",
    "        #if split == \"train\":\n",
    "            #self.inputs = (self.inputs - global_mean)/global_std\n",
    "            \n",
    "            #self.outputs = (self.outputs - global_mean)/global_std\n",
    "        #else:\n",
    "            #self.inputs = (self.inputs - global_mean)/global_std\n",
    "            #self.outputs = (self.outputs - global_mean)/global_std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'miami' \n",
    "split = 'train'\n",
    "train_dataset  = ArgoverseDataset(split = split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a174510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2779.01081344 1063.5660105 ]]]\n",
      "4124.162302888706\n"
     ]
    }
   ],
   "source": [
    "val_dataset = ArgoverseDataset(split = 'val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a44d7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40765\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(len(val_dataset))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa73bd",
   "metadata": {},
   "source": [
    "batch_sz = 16  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d1f0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64# batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee5b7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "# Linear Regression\n",
    "class LR(torch.nn.Module):\n",
    "    def __init__(self, input_dim, out_dim):\n",
    "        super(LR, self).__init__()\n",
    "        self.model = nn.Linear(input_dim, out_dim).cuda() # input_dim = input_length*2\n",
    "        \n",
    "    def forward(self, x, output_steps): \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        outputs = []\n",
    "        for i in range(output_steps):\n",
    "            out = self.model(x)    \n",
    "            outputs.append(out)\n",
    "            x = torch.cat([x[:,2:],  out], dim = 1)\n",
    "            \n",
    "        outputs = torch.cat(outputs, dim = 1)\n",
    "        return outputs.reshape(outputs.shape[0], output_steps, 2)\n",
    "    \n",
    "model = LR(input_dim = 50 * 2, out_dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adbc1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pred = model\n",
    "pred.to(device)\n",
    "#opt = optim.SGD(pred.parameters(),  lr=0.005)\n",
    "opt = optim.Adam(pred.parameters(), lr=.0008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4725237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 142482.76895137384\n",
      "epoch 1 loss: 139067.3133311512\n",
      "epoch 2 loss: 138263.92298756246\n",
      "epoch 3 loss: 137519.7380649174\n",
      "epoch 4 loss: 137106.3895408354\n",
      "epoch 5 loss: 136554.22388873625\n",
      "epoch 6 loss: 135953.06998490944\n",
      "epoch 7 loss: 135621.22173206368\n",
      "epoch 8 loss: 135005.71122904358\n",
      "epoch 9 loss: 134523.1713359351\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8392\\2373214343.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# scalars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_p37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs, outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "global_mean = np.mean(inputs, axis = (0,1), keepdims = True)\n",
    "global_std = np.std(np.sqrt(inputs[:, :, 0]**2 + inputs[:, :, 0]**2))\n",
    "gm = torch.from_numpy(global_mean).to(device)\n",
    "gs = (global_std)\n",
    "for epoch in range(20):\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, out = sample_batch\n",
    "        inp = inp.to(device)\n",
    "        out = out.to(device)\n",
    "        preds = pred(inp.float(),60)\n",
    "        \n",
    "        loss = ((preds - out) ** 2).sum()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print('epoch {} loss: {}'.format(epoch, total_loss / len(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da57dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 131139.51032478898\n"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz)\n",
    "inputs, outputs = get_cities_trajectories(split=\"val\")\n",
    "val_loss = 0\n",
    "global_mean = np.mean(inputs, axis = (0,1), keepdims = True)\n",
    "global_std = np.std(np.sqrt(inputs[:, :, 0]**2 + inputs[:, :, 0]**2))\n",
    "gm = torch.from_numpy(global_mean).to(device)\n",
    "gs = (global_std)\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, out = sample_batch\n",
    "    inp, out = inp.to(device), out.to(device)\n",
    "   # print(out.size())\n",
    "    preds = pred(inp.float(),60)\n",
    "    #preds = (preds * gs ) + gm\n",
    "    loss = ((preds - out) ** 2).sum()\n",
    "    val_loss += loss.item()\n",
    "print('loss: {}'.format(val_loss / len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 50, 2]) torch.Size([64, 60, 2])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    print(inp.shape, out.shape)\n",
    "    break\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "      implement your Deep learning model\n",
    "      implement training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch)\n",
    "    break\n",
    "def get_traj_pred(test_traj_in):\n",
    "    test_data = torch.tensor(test_traj_in).to(device)\n",
    "    test_preds = pred(test_data.float(),60)\n",
    "    #est_preds.detach().numpy()\n",
    "    return test_preds.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1dc483df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR(\n",
      "  (model): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00333419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing city austin\n",
      "(6325, 50, 2)\n",
      "(6325, 60, 2)\n",
      "(6325, 120)\n",
      "Processing city miami\n",
      "(7971, 50, 2)\n",
      "(7971, 60, 2)\n",
      "(7971, 120)\n",
      "Processing city pittsburgh\n",
      "(6361, 50, 2)\n",
      "(6361, 60, 2)\n",
      "(6361, 120)\n",
      "Processing city dearborn\n",
      "(3671, 50, 2)\n",
      "(3671, 60, 2)\n",
      "(3671, 120)\n",
      "Processing city washington-dc\n",
      "(3829, 50, 2)\n",
      "(3829, 60, 2)\n",
      "(3829, 120)\n",
      "Processing city palo-alto\n",
      "(1686, 50, 2)\n",
      "(1686, 60, 2)\n",
      "(1686, 120)\n"
     ]
    }
   ],
   "source": [
    "num_pred_steps=60\n",
    "all_preds = np.zeros(shape=(0, num_pred_steps * 2))\n",
    "city_col = np.array([])\n",
    "\n",
    "for city_name in cities:\n",
    "\n",
    "    print(\"Processing city\", city_name)\n",
    "    \n",
    "    test_traj_in, test_traj_out = get_city_trajectories(city=city_name, split=\"test\")\n",
    "    print(test_traj_in.shape)\n",
    "    \n",
    "    test_pred_arr = get_traj_pred(test_traj_in)\n",
    "    print(test_pred_arr.shape)\n",
    "    \n",
    "    test_pred_arr_reshaped = np.reshape(test_pred_arr, newshape=(test_traj_in.shape[0], num_pred_steps * 2))\n",
    "    print(test_pred_arr_reshaped.shape)\n",
    "\n",
    "    all_preds = np.r_[all_preds, test_pred_arr_reshaped]\n",
    "    city_col = np.r_[city_col, [str(i) + \"_\" + city_name for i in range(test_pred_arr.shape[0])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a2eec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sub_df = pd.DataFrame(np.c_[city_col, all_preds], columns=[np.r_[[\"ID\"], [\"v\" + str(i) for i in range(120)]]])\n",
    "sub_df.to_csv('linearRegression1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6d26468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v110</th>\n",
       "      <th>v111</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v114</th>\n",
       "      <th>v115</th>\n",
       "      <th>v116</th>\n",
       "      <th>v117</th>\n",
       "      <th>v118</th>\n",
       "      <th>v119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29838</th>\n",
       "      <td>1681_palo-alto</td>\n",
       "      <td>-1296.938354</td>\n",
       "      <td>-317.593842</td>\n",
       "      <td>-1360.113647</td>\n",
       "      <td>-432.915009</td>\n",
       "      <td>-1360.436157</td>\n",
       "      <td>-443.811890</td>\n",
       "      <td>-1366.592163</td>\n",
       "      <td>-438.407410</td>\n",
       "      <td>-1374.495483</td>\n",
       "      <td>...</td>\n",
       "      <td>-1385.634644</td>\n",
       "      <td>-455.768433</td>\n",
       "      <td>-1386.546143</td>\n",
       "      <td>-461.132172</td>\n",
       "      <td>-1388.461670</td>\n",
       "      <td>-459.146240</td>\n",
       "      <td>-1380.809937</td>\n",
       "      <td>-454.081055</td>\n",
       "      <td>-1384.614868</td>\n",
       "      <td>-459.819000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29839</th>\n",
       "      <td>1682_palo-alto</td>\n",
       "      <td>133.752014</td>\n",
       "      <td>-168.185791</td>\n",
       "      <td>137.953461</td>\n",
       "      <td>-53.074100</td>\n",
       "      <td>129.624451</td>\n",
       "      <td>-48.918953</td>\n",
       "      <td>129.056076</td>\n",
       "      <td>-52.447479</td>\n",
       "      <td>131.411514</td>\n",
       "      <td>...</td>\n",
       "      <td>130.320023</td>\n",
       "      <td>-34.802097</td>\n",
       "      <td>129.449585</td>\n",
       "      <td>-33.509361</td>\n",
       "      <td>130.614258</td>\n",
       "      <td>-34.807350</td>\n",
       "      <td>128.227402</td>\n",
       "      <td>-37.048088</td>\n",
       "      <td>128.762329</td>\n",
       "      <td>-35.630714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29840</th>\n",
       "      <td>1683_palo-alto</td>\n",
       "      <td>-1437.814331</td>\n",
       "      <td>2159.347900</td>\n",
       "      <td>-1438.039795</td>\n",
       "      <td>2161.934326</td>\n",
       "      <td>-1438.383911</td>\n",
       "      <td>2162.068359</td>\n",
       "      <td>-1438.486694</td>\n",
       "      <td>2162.055908</td>\n",
       "      <td>-1438.495361</td>\n",
       "      <td>...</td>\n",
       "      <td>-1433.952271</td>\n",
       "      <td>2158.454346</td>\n",
       "      <td>-1433.804321</td>\n",
       "      <td>2158.375000</td>\n",
       "      <td>-1433.615967</td>\n",
       "      <td>2158.238770</td>\n",
       "      <td>-1433.540527</td>\n",
       "      <td>2158.074951</td>\n",
       "      <td>-1433.372437</td>\n",
       "      <td>2158.020996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29841</th>\n",
       "      <td>1684_palo-alto</td>\n",
       "      <td>986.874146</td>\n",
       "      <td>1293.890869</td>\n",
       "      <td>1042.423462</td>\n",
       "      <td>1367.714233</td>\n",
       "      <td>1045.028809</td>\n",
       "      <td>1376.545044</td>\n",
       "      <td>1050.776489</td>\n",
       "      <td>1372.824829</td>\n",
       "      <td>1057.262573</td>\n",
       "      <td>...</td>\n",
       "      <td>1069.884033</td>\n",
       "      <td>1380.907349</td>\n",
       "      <td>1070.914185</td>\n",
       "      <td>1385.210815</td>\n",
       "      <td>1072.303589</td>\n",
       "      <td>1383.636475</td>\n",
       "      <td>1066.116821</td>\n",
       "      <td>1379.604370</td>\n",
       "      <td>1069.384888</td>\n",
       "      <td>1384.231689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29842</th>\n",
       "      <td>1685_palo-alto</td>\n",
       "      <td>-232.771332</td>\n",
       "      <td>593.715393</td>\n",
       "      <td>-127.262581</td>\n",
       "      <td>442.048340</td>\n",
       "      <td>-100.314964</td>\n",
       "      <td>449.865479</td>\n",
       "      <td>-87.291542</td>\n",
       "      <td>451.581055</td>\n",
       "      <td>-80.366112</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.307930</td>\n",
       "      <td>429.566803</td>\n",
       "      <td>-53.646492</td>\n",
       "      <td>435.490417</td>\n",
       "      <td>-53.624962</td>\n",
       "      <td>435.860443</td>\n",
       "      <td>-60.354939</td>\n",
       "      <td>433.429779</td>\n",
       "      <td>-54.685375</td>\n",
       "      <td>439.759613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID           v0           v1           v2           v3  \\\n",
       "29838  1681_palo-alto -1296.938354  -317.593842 -1360.113647  -432.915009   \n",
       "29839  1682_palo-alto   133.752014  -168.185791   137.953461   -53.074100   \n",
       "29840  1683_palo-alto -1437.814331  2159.347900 -1438.039795  2161.934326   \n",
       "29841  1684_palo-alto   986.874146  1293.890869  1042.423462  1367.714233   \n",
       "29842  1685_palo-alto  -232.771332   593.715393  -127.262581   442.048340   \n",
       "\n",
       "                v4           v5           v6           v7           v8  ...  \\\n",
       "29838 -1360.436157  -443.811890 -1366.592163  -438.407410 -1374.495483  ...   \n",
       "29839   129.624451   -48.918953   129.056076   -52.447479   131.411514  ...   \n",
       "29840 -1438.383911  2162.068359 -1438.486694  2162.055908 -1438.495361  ...   \n",
       "29841  1045.028809  1376.545044  1050.776489  1372.824829  1057.262573  ...   \n",
       "29842  -100.314964   449.865479   -87.291542   451.581055   -80.366112  ...   \n",
       "\n",
       "              v110         v111         v112         v113         v114  \\\n",
       "29838 -1385.634644  -455.768433 -1386.546143  -461.132172 -1388.461670   \n",
       "29839   130.320023   -34.802097   129.449585   -33.509361   130.614258   \n",
       "29840 -1433.952271  2158.454346 -1433.804321  2158.375000 -1433.615967   \n",
       "29841  1069.884033  1380.907349  1070.914185  1385.210815  1072.303589   \n",
       "29842   -58.307930   429.566803   -53.646492   435.490417   -53.624962   \n",
       "\n",
       "              v115         v116         v117         v118         v119  \n",
       "29838  -459.146240 -1380.809937  -454.081055 -1384.614868  -459.819000  \n",
       "29839   -34.807350   128.227402   -37.048088   128.762329   -35.630714  \n",
       "29840  2158.238770 -1433.540527  2158.074951 -1433.372437  2158.020996  \n",
       "29841  1383.636475  1066.116821  1379.604370  1069.384888  1384.231689  \n",
       "29842   435.860443   -60.354939   433.429779   -54.685375   439.759613  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('linearRegression1.csv')\n",
    "sample_sub.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e225e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
